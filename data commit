from bs4 import BeautifulSoup
import requests
import pandas as pd

def scrape_website(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')

    table = soup.find('table')
    headers = [header.text for header in table.find_all('th')]
    rows = []

    for row in table.find_all('tr')[1:]:
        cells = row.find_all('td')
        rows.append([cell.text.strip() for cell in cells])

    return headers, rows

def save_to_csv(headers, rows, filename):
    df = pd.DataFrame(rows, columns=headers)
    df.to_csv(filename, index=False)

url = 'https://example.com/data-table'
headers, rows = scrape_website(url)
save_to_csv(headers, rows, 'output.csv')
print("Данные сохранены в файл output.csv")
